---
layout: default
title: Open Position: VeriDRL - Verification of Deep Reinforcement Learning Applications
---

<div class="post"> <h2> {{page.title}} </h2>

     <p><span class="dropcap">W</span>e welcome applications for a PhD
     student position on extending applicability of formal
     verification for safety properties of Deep Reinforcement Learning
     (DRL) based applications. The Phd student position is hosted by
     the <a href="https://www.ida.liu.se/labs/eslab/">Embedded Systems
     Laboratory (ESLAB)</a> at the <a
     href="https://liu.se/en/organisation/liu/ida/sas">Software and
     Systems Division</a> in <a href="https://liu.se/">Link√∂ping
     University</a>. The position is fully funded by the CUGS Graduate
     School in Computer Science.</p>

     <h3>Qualifications</h3>	

    <ul>
    <li>See CUGS announcement for required specifications that are
    specific to the the <a href="https://www.ida.liu.se/ext/cugs/">CUGS doctoral school</a>.</li>
    <li>Experience with independently identifying non-trivial goals,
    to plan the work and to conduct it.</li>
    <li>Interest and maturity in terms of Mathematical proofs, Logic
    and Probabilities are central to the project (should be witnessed
    by excellent performances in corresponding courses, in projects or
    in publications)</li>
    <li>Experience with software development of mid-to-large projects
    is important as the techniques generated by the project will
    result in developing/coding/modifying open source tools to
    showcase the results.</li>
    </ul>

    <p>Observe that: </p>
    <ul>
    <li>Current state of the art can only handle "very small" neural
    networks. The project is about scaling up the size by coming up
    with new techniques to extend applicability of formal
    verification.</li>
    <li>Important: the project IS NOT about training and using DNNs
    models. It is about verifying DNN models behave correctly in DRL
    Applications.</li>
    </ul>


     <h3>The PhD Thesis Project</h3>	

     <p><b> Mission: </b>The VeriDRL project will extend the
     applicability of ML centered formal verification techniques to
     scale to realistic Deep Reinforcement Learning (DRL) systems. For
     this, it will focus on small systems meant to run on embedded
     devices. It will develop new verification techniques and account
     for stochastic behaviors. The project will also investigate
     possibilities to synthesize correct DRL systems.</p>

     <p> <b> Motivation: </b> Interest in control applications of
     reinforcement learning in general, and in those meant to run on
     small embedded devices in particular, is increasing. In such a
     system, the behavior of the environment might be known a priori
     or might need to be explored. A DRL solution will read the state
     of the system, perform an action according to the some policy,
     and obtain as a result a new state of the environment and a new
     reward. Given the central role of such policies and their direct
     impact on safety-critical systems (e.g., autonomous drones or
     insulin pumps), the verification problem of the resulting systems
     is particularly relevant.  </p>

     <p> <b>Scientific challenge: </b> Recent development in ML
     verification mainly focus on simple properties such as local
     robustness of classification for given inputs. Those targeting
     verification of DRL systems come with many challenges and
     opportunities for research:</p>

     <ul>
     <li> Scalability: Verification of DRL policies requires
     developing adapted and more scalable verification approaches for
     DNNs as they will target sequences of actions, not just the
     output to a single input. </li>
     <li> Stochastic behavior: controlled systems are often assumed to
     exhibit a stochastic behavior as capturing all details of their
     behavior is out-of-reach. </li>
     <li> Exploration: in fact a model for the controlled system might
     not even be available and one is left with samples of possible
     interactions. A question is then what guarantees can one enforce
     during exploration?</li>
     </ul>

     <h3> More information </h3>

     <p>This project will be supervised by < a href="mailto:ahmed.rezine@liu.se">Ahmed Rezine</a> (main
     supervisor) and <a href="mailto:soheil.samii@liu.se">Soheil Samii</a> (assistant supervisor). More
     information can be found <a
     href="https://rezahmed.github.io/veridrl/.">here</a>. Feel free
     to contact Ahmed for further information about the call.</p>

</div>

